{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7324c6c6",
   "metadata": {},
   "source": [
    "# For Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52ec11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "Threshold = 0.3\n",
    "image_size= 320\n",
    "\n",
    "def final_prediction(prediction_box, bounding_box, confidence, class_labels, width_ratio, height_ratio):\n",
    "    if len(prediction_box) > 0:\n",
    "        for k in prediction_box.flatten():\n",
    "            x, y, w, h =bounding_box[k]\n",
    "            x=int(x*width_ratio)\n",
    "            y=int(y*height_ratio)\n",
    "            w=int(w*width_ratio)\n",
    "            h=int(h*height_ratio)\n",
    "            conf_level = str(round(confidence[k], 2))\n",
    "            label = str(classes_names[class_labels[k]])\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 2)\n",
    "            cv2.putText(frame, label+' '+conf_level, (x,y-2),font,2,(255,0,0),2)\n",
    "            \n",
    "def bounding_box_prediction(output_data):\n",
    "    bounding_box=[]\n",
    "    class_labels=[]\n",
    "    confidence_score = []\n",
    "    for i in output_data:\n",
    "        for j in i:\n",
    "            high_label = j[5:]\n",
    "            class_ids = np.argmax(high_label)\n",
    "            confidence = high_label[class_ids]\n",
    "            \n",
    "            if confidence > Threshold:\n",
    "                w, h = int(j[2] * image_size), int(j[3]*image_size)\n",
    "                x, y = int(j[0] * image_size-w/2), int(j[1]*image_size-h/2)\n",
    "                bounding_box.append([x,y,w,h])\n",
    "                class_labels.append(class_ids)\n",
    "                confidence_score.append(confidence)\n",
    "                \n",
    "    prediction_box = cv2.dnn.NMSBoxes(bounding_box, confidence_score, Threshold, .3)\n",
    "    return prediction_box, bounding_box, confidence_score, class_labels\n",
    "\n",
    "image=cv2.VideoCapture('./car_counting.mp4')\n",
    "while image.read():\n",
    "    res, frame = image.read()\n",
    "    if res == True:\n",
    "        original_width, original_height = frame.shape[1], frame.shape[0]\n",
    "        \n",
    "        Neural_Network = cv2.dnn.readNetFromDarknet('./yolov3 (1).cfg','./yolov3.weights')\n",
    "        classes_names = []\n",
    "        k = open('./class_names','r')\n",
    "        for i in k.readlines():\n",
    "            classes_names.append(i.strip())\n",
    "        #print(classes_names)\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255, (320,320), True, crop=False)\n",
    "        #print(blob.shape)\n",
    "        Neural_Network.setInput(blob)\n",
    "        cfg_data = Neural_Network.getLayerNames()\n",
    "        #print(cfg_data)\n",
    "        layer_names = Neural_Network.getUnconnectedOutLayers()\n",
    "        outputs=[cfg_data[i-1] for i in layer_names]\n",
    "        #print(outputs)\n",
    "        output_data = Neural_Network.forward(outputs)\n",
    "        prediction_box, bounding_box, confidence, class_labels = bounding_box_prediction(output_data)\n",
    "        \n",
    "        final_prediction(prediction_box, bounding_box, confidence, class_labels, original_width/320, original_height/320)\n",
    "        \n",
    "        cv2.imshow('YOLO Algorithm', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682f81e",
   "metadata": {},
   "source": [
    "# Saving Each Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5d59c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import os\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "Threshold = 0.3\n",
    "image_size = 320\n",
    "\n",
    "\n",
    "def final_prediction(prediction_box , bounding_box , confidence , class_labels,width_ratio,height_ratio):\n",
    "    if len(prediction_box) > 0:\n",
    "        for k in prediction_box.flatten():\n",
    "            x , y , w , h = bounding_box[k]\n",
    "            x = int(x * width_ratio)\n",
    "            y = int(y * height_ratio)\n",
    "            w = int(w * width_ratio)\n",
    "            h = int(h * height_ratio)\n",
    "            conf_level = str(round(confidence[k] , 2))\n",
    "            label = str(classes_names[class_labels[k]])\n",
    "            cv2.rectangle(frame , (x,y),(x+w , y+h),(0,0,255),2)\n",
    "            cv2.putText(frame ,label+' '+conf_level,(x,y-2),font,0.5,(255,0,0,),1)\n",
    "\n",
    "def bounding_box_prediction(output_data):\n",
    "    bounding_box = []\n",
    "    class_labels = []\n",
    "    confidence_score = []\n",
    "    for i in output_data:\n",
    "        for j in i:\n",
    "            high_label = j[5:]\n",
    "            classes_ids = np.argmax(high_label)\n",
    "            confidence = high_label[classes_ids]\n",
    "            \n",
    "            if confidence > Threshold:\n",
    "                w , h = int(j[2] * image_size) , int(j[3] * image_size)\n",
    "                x , y = int(j[0] * image_size - w/2) , int(j[1] * image_size - h/2)\n",
    "                bounding_box.append([x,y,w,h])\n",
    "                class_labels.append(classes_ids)\n",
    "                confidence_score.append(confidence)\n",
    "\n",
    "    prediction_boxes = cv2.dnn.NMSBoxes(bounding_box , confidence_score , Threshold , .3)    \n",
    "    return prediction_boxes , bounding_box ,confidence_score,class_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "image = cv2.VideoCapture('./car_counting.mp4')\n",
    "while image.read():\n",
    "    res , frame = image.read()\n",
    "    if res == True:\n",
    "        original_with , original_height = frame.shape[1] , frame.shape[0]\n",
    "\n",
    "        Neural_Network = cv2.dnn.readNetFromDarknet('./yolov3 (1).cfg','./yolov3.weights')\n",
    "        classes_names = []\n",
    "        k = open('./class_names','r')\n",
    "        for i in k.readlines():\n",
    "            classes_names.append(i.strip())\n",
    "        #print(classes_names)\n",
    "        blob = cv2.dnn.blobFromImage(frame , 1/255 , (320,320) , True , crop = False)\n",
    "        #print(blob.shape)\n",
    "        Neural_Network.setInput(blob)\n",
    "        cfg_data = Neural_Network.getLayerNames()\n",
    "        #print(cfg_data)\n",
    "        layer_names = Neural_Network.getUnconnectedOutLayers()\n",
    "        outputs = [cfg_data[i-1] for i in layer_names]\n",
    "        #print(outputs)\n",
    "        output_data = Neural_Network.forward(outputs)\n",
    "        prediction_box , bounding_box , confidence , class_labels = bounding_box_prediction(output_data)\n",
    "\n",
    "        final_prediction(prediction_box , bounding_box , confidence , class_labels , original_with / 320 , original_height / 320 )\n",
    "        cv2.imwrite('./Frame/%d.jpg'%count,frame)\n",
    "        cv2.imshow('YOLO Algorithm', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        count+=1\n",
    "    else:\n",
    "        break \n",
    "\n",
    "image.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2656645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining All the frames and making as a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2ed114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.jpg', '1.jpg', '10.jpg', '100.jpg', '101.jpg', '102.jpg', '103.jpg', '104.jpg', '105.jpg', '106.jpg', '107.jpg', '108.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg', '2.jpg', '20.jpg', '21.jpg', '22.jpg', '23.jpg', '24.jpg', '25.jpg', '26.jpg', '27.jpg', '28.jpg', '29.jpg', '3.jpg', '30.jpg', '31.jpg', '32.jpg', '33.jpg', '34.jpg', '35.jpg', '36.jpg', '37.jpg', '38.jpg', '39.jpg', '4.jpg', '40.jpg', '41.jpg', '42.jpg', '43.jpg', '44.jpg', '45.jpg', '46.jpg', '47.jpg', '48.jpg', '49.jpg', '5.jpg', '50.jpg', '51.jpg', '52.jpg', '53.jpg', '54.jpg', '55.jpg', '56.jpg', '57.jpg', '58.jpg', '59.jpg', '6.jpg', '60.jpg', '61.jpg', '62.jpg', '63.jpg', '64.jpg', '65.jpg', '66.jpg', '67.jpg', '68.jpg', '69.jpg', '7.jpg', '70.jpg', '71.jpg', '72.jpg', '73.jpg', '74.jpg', '75.jpg', '76.jpg', '77.jpg', '78.jpg', '79.jpg', '8.jpg', '80.jpg', '81.jpg', '82.jpg', '83.jpg', '84.jpg', '85.jpg', '86.jpg', '87.jpg', '88.jpg', '89.jpg', '9.jpg', '90.jpg', '91.jpg', '92.jpg', '93.jpg', '94.jpg', '95.jpg', '96.jpg', '97.jpg', '98.jpg', '99.jpg']\n"
     ]
    }
   ],
   "source": [
    "c=[]\n",
    "for i in os.listdir('./Frame/'):\n",
    "    c.append(i)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a4e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34972b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.jpg',\n",
       " '1.jpg',\n",
       " '2.jpg',\n",
       " '3.jpg',\n",
       " '4.jpg',\n",
       " '5.jpg',\n",
       " '6.jpg',\n",
       " '7.jpg',\n",
       " '8.jpg',\n",
       " '9.jpg',\n",
       " '10.jpg',\n",
       " '11.jpg',\n",
       " '12.jpg',\n",
       " '13.jpg',\n",
       " '14.jpg',\n",
       " '15.jpg',\n",
       " '16.jpg',\n",
       " '17.jpg',\n",
       " '18.jpg',\n",
       " '19.jpg',\n",
       " '20.jpg',\n",
       " '21.jpg',\n",
       " '22.jpg',\n",
       " '23.jpg',\n",
       " '24.jpg',\n",
       " '25.jpg',\n",
       " '26.jpg',\n",
       " '27.jpg',\n",
       " '28.jpg',\n",
       " '29.jpg',\n",
       " '30.jpg',\n",
       " '31.jpg',\n",
       " '32.jpg',\n",
       " '33.jpg',\n",
       " '34.jpg',\n",
       " '35.jpg',\n",
       " '36.jpg',\n",
       " '37.jpg',\n",
       " '38.jpg',\n",
       " '39.jpg',\n",
       " '40.jpg',\n",
       " '41.jpg',\n",
       " '42.jpg',\n",
       " '43.jpg',\n",
       " '44.jpg',\n",
       " '45.jpg',\n",
       " '46.jpg',\n",
       " '47.jpg',\n",
       " '48.jpg',\n",
       " '49.jpg',\n",
       " '50.jpg',\n",
       " '51.jpg',\n",
       " '52.jpg',\n",
       " '53.jpg',\n",
       " '54.jpg',\n",
       " '55.jpg',\n",
       " '56.jpg',\n",
       " '57.jpg',\n",
       " '58.jpg',\n",
       " '59.jpg',\n",
       " '60.jpg',\n",
       " '61.jpg',\n",
       " '62.jpg',\n",
       " '63.jpg',\n",
       " '64.jpg',\n",
       " '65.jpg',\n",
       " '66.jpg',\n",
       " '67.jpg',\n",
       " '68.jpg',\n",
       " '69.jpg',\n",
       " '70.jpg',\n",
       " '71.jpg',\n",
       " '72.jpg',\n",
       " '73.jpg',\n",
       " '74.jpg',\n",
       " '75.jpg',\n",
       " '76.jpg',\n",
       " '77.jpg',\n",
       " '78.jpg',\n",
       " '79.jpg',\n",
       " '80.jpg',\n",
       " '81.jpg',\n",
       " '82.jpg',\n",
       " '83.jpg',\n",
       " '84.jpg',\n",
       " '85.jpg',\n",
       " '86.jpg',\n",
       " '87.jpg',\n",
       " '88.jpg',\n",
       " '89.jpg',\n",
       " '90.jpg',\n",
       " '91.jpg',\n",
       " '92.jpg',\n",
       " '93.jpg',\n",
       " '94.jpg',\n",
       " '95.jpg',\n",
       " '96.jpg',\n",
       " '97.jpg',\n",
       " '98.jpg',\n",
       " '99.jpg',\n",
       " '100.jpg',\n",
       " '101.jpg',\n",
       " '102.jpg',\n",
       " '103.jpg',\n",
       " '104.jpg',\n",
       " '105.jpg',\n",
       " '106.jpg',\n",
       " '107.jpg',\n",
       " '108.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "c.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19f947ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = []\n",
    "for frame in c:\n",
    "    img = cv2.imread('./Frame/'+str(frame))\n",
    "    height, width, layers = img.shape\n",
    "    size = (width , height)\n",
    "    img_array.append(img)\n",
    "out = cv2.VideoWriter('./Result Video/output.mp4',cv2.VideoWriter_fourcc(*'XVID'),30.0,size)\n",
    "for l in range(len(img_array)):\n",
    "    out.write(img_array[l])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6bb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43717d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc282e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201813b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
